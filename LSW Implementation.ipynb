{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Kategorie ID</th>\n",
       "      <th>Unterkategorie ID</th>\n",
       "      <th>Ticket Label</th>\n",
       "      <th>Abteilung Label</th>\n",
       "      <th>...</th>\n",
       "      <th>stemmed_beschreibung</th>\n",
       "      <th>Produkt Label (Merged)</th>\n",
       "      <th>RandomForestClassifier Predictions</th>\n",
       "      <th>New Labels</th>\n",
       "      <th>SVC Predictions</th>\n",
       "      <th>MultinomialNB Predictions</th>\n",
       "      <th>LogisticRegression Predictions</th>\n",
       "      <th>KNeighborsClassifier Predictions</th>\n",
       "      <th>error_count</th>\n",
       "      <th>unique_error_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000014953</td>\n",
       "      <td>sehr geehrte damen und herren  leider wird mir...</td>\n",
       "      <td>2024-01-03 11:13:31</td>\n",
       "      <td>mandantenrücksetzung s77 mandant 303</td>\n",
       "      <td>ZSD_SR_S4HANA</td>\n",
       "      <td>ZSD_SR_S4HANA_MR</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Basis</td>\n",
       "      <td>...</td>\n",
       "      <td>mandantenrucksetz s77 mandant 303</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike,Entwicklungssystem bzw. Mandant</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>Entwicklungssystem bzw. Mandant</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2000014960</td>\n",
       "      <td>sehr geehrte damen und herren  ich hatte im de...</td>\n",
       "      <td>2024-01-08 08:34:13</td>\n",
       "      <td>prüfung am 3001 ab 1430 uhr</td>\n",
       "      <td>ZSD_SR_GUI</td>\n",
       "      <td></td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>prufung 3001 1430</td>\n",
       "      <td>global bike</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike,Sonstiges</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2000014961</td>\n",
       "      <td>from saad sameh ssaadshuacuk sent friday janua...</td>\n",
       "      <td>2024-01-08 09:17:17</td>\n",
       "      <td>financial accounting module</td>\n",
       "      <td>ZSD_SR_S4HANA</td>\n",
       "      <td>ZSD_SR_S4HANA_SON</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>financi account modul</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike,Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2000014962</td>\n",
       "      <td>sehr geehrte damen und herren  hiermit sende i...</td>\n",
       "      <td>2024-01-08 09:35:49</td>\n",
       "      <td>ts410 kursanmeldung</td>\n",
       "      <td>ZSD_SR_TERP</td>\n",
       "      <td>ZSD_SR_TERP_ANF</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>ts410 kursanmeld</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2000014964</td>\n",
       "      <td>hello  i am new to sap admin with your help i ...</td>\n",
       "      <td>2024-01-08 13:09:43</td>\n",
       "      <td>gui requirement</td>\n",
       "      <td>ZSD_SR_S4HANA</td>\n",
       "      <td>ZSD_SR_S4HANA_SON</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>gui requir</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0          ID  \\\n",
       "0             0           2  2000014953   \n",
       "1             1           9  2000014960   \n",
       "2             2          10  2000014961   \n",
       "3             3          11  2000014962   \n",
       "4             4          13  2000014964   \n",
       "\n",
       "                                                Text            Timestamp  \\\n",
       "0  sehr geehrte damen und herren  leider wird mir...  2024-01-03 11:13:31   \n",
       "1  sehr geehrte damen und herren  ich hatte im de...  2024-01-08 08:34:13   \n",
       "2  from saad sameh ssaadshuacuk sent friday janua...  2024-01-08 09:17:17   \n",
       "3  sehr geehrte damen und herren  hiermit sende i...  2024-01-08 09:35:49   \n",
       "4  hello  i am new to sap admin with your help i ...  2024-01-08 13:09:43   \n",
       "\n",
       "                            Beschreibung    Kategorie ID   Unterkategorie ID  \\\n",
       "0  mandantenrücksetzung s77 mandant 303   ZSD_SR_S4HANA    ZSD_SR_S4HANA_MR    \n",
       "1           prüfung am 3001 ab 1430 uhr      ZSD_SR_GUI                        \n",
       "2           financial accounting module   ZSD_SR_S4HANA   ZSD_SR_S4HANA_SON    \n",
       "3                   ts410 kursanmeldung     ZSD_SR_TERP     ZSD_SR_TERP_ANF    \n",
       "4                       gui requirement   ZSD_SR_S4HANA   ZSD_SR_S4HANA_SON    \n",
       "\n",
       "  Ticket Label Abteilung Label  ...               stemmed_beschreibung  \\\n",
       "0     2. Level           Basis  ...  mandantenrucksetz s77 mandant 303   \n",
       "1     2. Level     Applikation  ...                  prufung 3001 1430   \n",
       "2     2. Level     Applikation  ...              financi account modul   \n",
       "3     2. Level     Applikation  ...                   ts410 kursanmeld   \n",
       "4     2. Level     Applikation  ...                         gui requir   \n",
       "\n",
       "  Produkt Label (Merged) RandomForestClassifier Predictions  \\\n",
       "0            global bike                        global bike   \n",
       "1            global bike                          Sonstiges   \n",
       "2              Sonstiges                        global bike   \n",
       "3                  TS410                              TS410   \n",
       "4            global bike                        global bike   \n",
       "\n",
       "                                    New Labels SVC Predictions  \\\n",
       "0  global bike,Entwicklungssystem bzw. Mandant     global bike   \n",
       "1                        global bike,Sonstiges       Sonstiges   \n",
       "2                        global bike,Sonstiges     global bike   \n",
       "3                                        TS410           TS410   \n",
       "4                                  global bike     global bike   \n",
       "\n",
       "  MultinomialNB Predictions LogisticRegression Predictions  \\\n",
       "0               global bike                    global bike   \n",
       "1                 Sonstiges                      Sonstiges   \n",
       "2               global bike                    global bike   \n",
       "3                     TS410                          TS410   \n",
       "4               global bike                    global bike   \n",
       "\n",
       "  KNeighborsClassifier Predictions error_count unique_error_count  \n",
       "0  Entwicklungssystem bzw. Mandant           1                  1  \n",
       "1                      global bike           4                  1  \n",
       "2                      global bike           5                  1  \n",
       "3                            TS410           0                  0  \n",
       "4                      global bike           0                  0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSW Mu;i Labelled Classification\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy.sparse\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from collections.abc import Sequence, Set\n",
    "\n",
    "dataset_dir_path = \"~/Desktop/thesis/data\"\n",
    "categorical_columns = ['Kategorie ID', 'Unterkategorie ID']\n",
    "\n",
    "tickets = pd.read_excel(f\"{dataset_dir_path}/tickets.xlsx\")\n",
    "\n",
    "tickets.head()\n",
    "# tickets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tickets['New Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Kategorie ID</th>\n",
       "      <th>Unterkategorie ID</th>\n",
       "      <th>Ticket Label</th>\n",
       "      <th>Abteilung Label</th>\n",
       "      <th>...</th>\n",
       "      <th>stemmed_beschreibung</th>\n",
       "      <th>Produkt Label (Merged)</th>\n",
       "      <th>RandomForestClassifier Predictions</th>\n",
       "      <th>SVC Predictions</th>\n",
       "      <th>MultinomialNB Predictions</th>\n",
       "      <th>LogisticRegression Predictions</th>\n",
       "      <th>KNeighborsClassifier Predictions</th>\n",
       "      <th>error_count</th>\n",
       "      <th>unique_error_count</th>\n",
       "      <th>New Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000014953</td>\n",
       "      <td>sehr geehrte damen und herren  leider wird mir...</td>\n",
       "      <td>2024-01-03 11:13:31</td>\n",
       "      <td>mandantenrücksetzung s77 mandant 303</td>\n",
       "      <td>ZSD_SR_S4HANA</td>\n",
       "      <td>ZSD_SR_S4HANA_MR</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Basis</td>\n",
       "      <td>...</td>\n",
       "      <td>mandantenrucksetz s77 mandant 303</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>Entwicklungssystem bzw. Mandant</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Entwicklungssystem bzw. Mandant,global bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2000014960</td>\n",
       "      <td>sehr geehrte damen und herren  ich hatte im de...</td>\n",
       "      <td>2024-01-08 08:34:13</td>\n",
       "      <td>prüfung am 3001 ab 1430 uhr</td>\n",
       "      <td>ZSD_SR_GUI</td>\n",
       "      <td></td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>prufung 3001 1430</td>\n",
       "      <td>global bike</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Sonstiges,global bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2000014961</td>\n",
       "      <td>from saad sameh ssaadshuacuk sent friday janua...</td>\n",
       "      <td>2024-01-08 09:17:17</td>\n",
       "      <td>financial accounting module</td>\n",
       "      <td>ZSD_SR_S4HANA</td>\n",
       "      <td>ZSD_SR_S4HANA_SON</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>financi account modul</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Sonstiges,global bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2000014962</td>\n",
       "      <td>sehr geehrte damen und herren  hiermit sende i...</td>\n",
       "      <td>2024-01-08 09:35:49</td>\n",
       "      <td>ts410 kursanmeldung</td>\n",
       "      <td>ZSD_SR_TERP</td>\n",
       "      <td>ZSD_SR_TERP_ANF</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>ts410 kursanmeld</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>TS410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TS410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2000014964</td>\n",
       "      <td>hello  i am new to sap admin with your help i ...</td>\n",
       "      <td>2024-01-08 13:09:43</td>\n",
       "      <td>gui requirement</td>\n",
       "      <td>ZSD_SR_S4HANA</td>\n",
       "      <td>ZSD_SR_S4HANA_SON</td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>gui requir</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>global bike</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0          ID  \\\n",
       "0             0           2  2000014953   \n",
       "1             1           9  2000014960   \n",
       "2             2          10  2000014961   \n",
       "3             3          11  2000014962   \n",
       "4             4          13  2000014964   \n",
       "\n",
       "                                                Text            Timestamp  \\\n",
       "0  sehr geehrte damen und herren  leider wird mir...  2024-01-03 11:13:31   \n",
       "1  sehr geehrte damen und herren  ich hatte im de...  2024-01-08 08:34:13   \n",
       "2  from saad sameh ssaadshuacuk sent friday janua...  2024-01-08 09:17:17   \n",
       "3  sehr geehrte damen und herren  hiermit sende i...  2024-01-08 09:35:49   \n",
       "4  hello  i am new to sap admin with your help i ...  2024-01-08 13:09:43   \n",
       "\n",
       "                            Beschreibung    Kategorie ID   Unterkategorie ID  \\\n",
       "0  mandantenrücksetzung s77 mandant 303   ZSD_SR_S4HANA    ZSD_SR_S4HANA_MR    \n",
       "1           prüfung am 3001 ab 1430 uhr      ZSD_SR_GUI                        \n",
       "2           financial accounting module   ZSD_SR_S4HANA   ZSD_SR_S4HANA_SON    \n",
       "3                   ts410 kursanmeldung     ZSD_SR_TERP     ZSD_SR_TERP_ANF    \n",
       "4                       gui requirement   ZSD_SR_S4HANA   ZSD_SR_S4HANA_SON    \n",
       "\n",
       "  Ticket Label Abteilung Label  ...               stemmed_beschreibung  \\\n",
       "0     2. Level           Basis  ...  mandantenrucksetz s77 mandant 303   \n",
       "1     2. Level     Applikation  ...                  prufung 3001 1430   \n",
       "2     2. Level     Applikation  ...              financi account modul   \n",
       "3     2. Level     Applikation  ...                   ts410 kursanmeld   \n",
       "4     2. Level     Applikation  ...                         gui requir   \n",
       "\n",
       "  Produkt Label (Merged) RandomForestClassifier Predictions SVC Predictions  \\\n",
       "0            global bike                        global bike     global bike   \n",
       "1            global bike                          Sonstiges       Sonstiges   \n",
       "2              Sonstiges                        global bike     global bike   \n",
       "3                  TS410                              TS410           TS410   \n",
       "4            global bike                        global bike     global bike   \n",
       "\n",
       "  MultinomialNB Predictions LogisticRegression Predictions  \\\n",
       "0               global bike                    global bike   \n",
       "1                 Sonstiges                      Sonstiges   \n",
       "2               global bike                    global bike   \n",
       "3                     TS410                          TS410   \n",
       "4               global bike                    global bike   \n",
       "\n",
       "  KNeighborsClassifier Predictions error_count unique_error_count  \\\n",
       "0  Entwicklungssystem bzw. Mandant           1                  1   \n",
       "1                      global bike           4                  1   \n",
       "2                      global bike           5                  1   \n",
       "3                            TS410           0                  0   \n",
       "4                      global bike           0                  0   \n",
       "\n",
       "                                    New Labels  \n",
       "0  Entwicklungssystem bzw. Mandant,global bike  \n",
       "1                        Sonstiges,global bike  \n",
       "2                        Sonstiges,global bike  \n",
       "3                                        TS410  \n",
       "4                                  global bike  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_new_labels(row):\n",
    "    # Get the values of the specified columns in the row\n",
    "    predictions = row[['Produkt Label (Merged)',\n",
    "                       'RandomForestClassifier Predictions',\n",
    "                       'SVC Predictions',\n",
    "                       'MultinomialNB Predictions',\n",
    "                       'LogisticRegression Predictions',\n",
    "                       'KNeighborsClassifier Predictions']]\n",
    "    # Count unique values that are strings (considered errors)\n",
    "    return ','.join(set(predictions))\n",
    "\n",
    "tickets['New Labels'] = tickets.apply(create_new_labels, axis=1)\n",
    "\n",
    "tickets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Beschreibung</th>\n",
       "      <th>Kategorie ID</th>\n",
       "      <th>Unterkategorie ID</th>\n",
       "      <th>Ticket Label</th>\n",
       "      <th>Abteilung Label</th>\n",
       "      <th>...</th>\n",
       "      <th>stemmed_beschreibung</th>\n",
       "      <th>Produkt Label (Merged)</th>\n",
       "      <th>RandomForestClassifier Predictions</th>\n",
       "      <th>SVC Predictions</th>\n",
       "      <th>MultinomialNB Predictions</th>\n",
       "      <th>LogisticRegression Predictions</th>\n",
       "      <th>KNeighborsClassifier Predictions</th>\n",
       "      <th>error_count</th>\n",
       "      <th>unique_error_count</th>\n",
       "      <th>New Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2000014968</td>\n",
       "      <td>hi team  singapore university of social scienc...</td>\n",
       "      <td>2024-01-10 04:05:00</td>\n",
       "      <td>request gbi 41 and erpsim for suss</td>\n",
       "      <td>ZSD_SR_KTV</td>\n",
       "      <td></td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Applikation</td>\n",
       "      <td>...</td>\n",
       "      <td>request gbi 41 erpsim suss</td>\n",
       "      <td>ERPsim</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>ERPsim</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Sonstiges,global bike,ERPsim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>2000015032</td>\n",
       "      <td>hi team  fpt university would like to exchange...</td>\n",
       "      <td>2024-01-30 02:59:30</td>\n",
       "      <td>request erpsim client for fpt</td>\n",
       "      <td>ZSD_SR_KTV</td>\n",
       "      <td></td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Vertrag</td>\n",
       "      <td>...</td>\n",
       "      <td>request erpsim client fpt</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>ERPsim</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>ERPsim</td>\n",
       "      <td>global bike</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Sonstiges,global bike,ERPsim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>86</td>\n",
       "      <td>2000015037</td>\n",
       "      <td>hi team  brawijaya university brawijaya is usi...</td>\n",
       "      <td>2024-01-31 05:39:44</td>\n",
       "      <td>assign s25303 for brawijaya university</td>\n",
       "      <td>ZSD_SR_KTV</td>\n",
       "      <td></td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Vertrag</td>\n",
       "      <td>...</td>\n",
       "      <td>assign s25303 brawijaya univers</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>UCC Portal</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Sonstiges,UCC Portal,global bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>351</td>\n",
       "      <td>2000014055</td>\n",
       "      <td>hi team  the below request is contract renewal...</td>\n",
       "      <td>2023-02-03 06:24:41</td>\n",
       "      <td>contract renewal for its</td>\n",
       "      <td>ZSD_SR_KTV</td>\n",
       "      <td></td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Vertrag</td>\n",
       "      <td>...</td>\n",
       "      <td>contract renew</td>\n",
       "      <td>ERPsim</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>global bike,Sonstiges,ERPsim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>263</td>\n",
       "      <td>457</td>\n",
       "      <td>2000014161</td>\n",
       "      <td>hi team  sorry for the late notice because we ...</td>\n",
       "      <td>2023-03-14 05:29:16</td>\n",
       "      <td>contract expired for uajy</td>\n",
       "      <td>ZSD_SR_KTV</td>\n",
       "      <td></td>\n",
       "      <td>2. Level</td>\n",
       "      <td>Vertrag</td>\n",
       "      <td>...</td>\n",
       "      <td>contract expir uaji</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>global bike</td>\n",
       "      <td>Sonstiges</td>\n",
       "      <td>global bike</td>\n",
       "      <td>UCC Portal</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Sonstiges,UCC Portal,global bike</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0          ID  \\\n",
       "8               8          17  2000014968   \n",
       "41             41          81  2000015032   \n",
       "44             44          86  2000015037   \n",
       "201           201         351  2000014055   \n",
       "263           263         457  2000014161   \n",
       "\n",
       "                                                  Text            Timestamp  \\\n",
       "8    hi team  singapore university of social scienc...  2024-01-10 04:05:00   \n",
       "41   hi team  fpt university would like to exchange...  2024-01-30 02:59:30   \n",
       "44   hi team  brawijaya university brawijaya is usi...  2024-01-31 05:39:44   \n",
       "201  hi team  the below request is contract renewal...  2023-02-03 06:24:41   \n",
       "263  hi team  sorry for the late notice because we ...  2023-03-14 05:29:16   \n",
       "\n",
       "                                Beschreibung Kategorie ID Unterkategorie ID  \\\n",
       "8        request gbi 41 and erpsim for suss   ZSD_SR_KTV                      \n",
       "41            request erpsim client for fpt   ZSD_SR_KTV                      \n",
       "44   assign s25303 for brawijaya university   ZSD_SR_KTV                      \n",
       "201                contract renewal for its   ZSD_SR_KTV                      \n",
       "263               contract expired for uajy   ZSD_SR_KTV                      \n",
       "\n",
       "    Ticket Label Abteilung Label  ...             stemmed_beschreibung  \\\n",
       "8       2. Level     Applikation  ...       request gbi 41 erpsim suss   \n",
       "41      2. Level         Vertrag  ...        request erpsim client fpt   \n",
       "44      2. Level         Vertrag  ...  assign s25303 brawijaya univers   \n",
       "201     2. Level         Vertrag  ...                   contract renew   \n",
       "263     2. Level         Vertrag  ...              contract expir uaji   \n",
       "\n",
       "    Produkt Label (Merged) RandomForestClassifier Predictions SVC Predictions  \\\n",
       "8                   ERPsim                          Sonstiges          ERPsim   \n",
       "41               Sonstiges                          Sonstiges          ERPsim   \n",
       "44               Sonstiges                        global bike     global bike   \n",
       "201                 ERPsim                        global bike     global bike   \n",
       "263              Sonstiges                        global bike     global bike   \n",
       "\n",
       "    MultinomialNB Predictions LogisticRegression Predictions  \\\n",
       "8                   Sonstiges                    global bike   \n",
       "41                  Sonstiges                         ERPsim   \n",
       "44                  Sonstiges                    global bike   \n",
       "201                 Sonstiges                    global bike   \n",
       "263                 Sonstiges                    global bike   \n",
       "\n",
       "    KNeighborsClassifier Predictions error_count unique_error_count  \\\n",
       "8                        global bike           4                  2   \n",
       "41                       global bike           3                  2   \n",
       "44                        UCC Portal           4                  2   \n",
       "201                      global bike           5                  2   \n",
       "263                       UCC Portal           4                  2   \n",
       "\n",
       "                           New Labels  \n",
       "8        Sonstiges,global bike,ERPsim  \n",
       "41       Sonstiges,global bike,ERPsim  \n",
       "44   Sonstiges,UCC Portal,global bike  \n",
       "201      global bike,Sonstiges,ERPsim  \n",
       "263  Sonstiges,UCC Portal,global bike  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column 'error_count'\n",
    "pred_cols = ['RandomForestClassifier Predictions',\n",
    "                       'SVC Predictions',\n",
    "                       'MultinomialNB Predictions',\n",
    "                       'LogisticRegression Predictions',\n",
    "                       'KNeighborsClassifier Predictions']\n",
    "\n",
    "tickets['error_count'] = tickets.apply(lambda row: sum(row[col] != row['Produkt Label (Merged)'] for col in pred_cols), axis=1)\n",
    "\n",
    "tickets['unique_error_count'] = tickets[pred_cols + ['Produkt Label (Merged)']].apply(lambda row: len(set(row) - set(row['Produkt Label (Merged)'])) - 1, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "incorrect_tickets = tickets[tickets['unique_error_count'] > 1]\n",
    "\n",
    "# TICKETS WITH 2 WRONG TICKETS !!! (There are none with 3)\n",
    "incorrect_tickets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZSD_SR_S4HANA ' 'ZSD_SR_GUI ' 'ZSD_SR_TERP ' 'ZSD_SR_GBI ' 'ZSD_SR_KTV '\n",
      " 'ZSD_SR_SIM ' 'ZSD_SR_S4SCH ' 'ZSD_SR_ES ' 'ZSD_SR_AA ' 'ZSD_SR_ISR '\n",
      " 'ZSD_SR_HANA ' 'ZSD_SR_BW ' 'ZSD_SR_IDES ' 'ZSD_SR_BYD ' 'ZSD_SR_BO '\n",
      " 'ZSD_SR_HCR ' 'ZSD_SR_AAT ' 'ZSD_SR_ERP4S ' 'ZSD_SR_CE ' 'ZSD_SR_EP '\n",
      " 'ZSD_SR_SOLM ' 'ZSD_SR_PI ' ' '] 23\n",
      "['GBI' 'Sonstiges' 'TS410' 'GBS/Digital Transformation Curriculum'\n",
      " 'ERPsim' 'Entwicklungssystem bzw. Mandant' 'SAP4School' 'UCC Portal'\n",
      " 'HANA' 'SAP Business Warehouse & Business Objects' 'IDES'\n",
      " 'Business By Design' 'Lumira' 'Celonis' 'UCC Hardware'] 15\n"
     ]
    }
   ],
   "source": [
    "categories = tickets['Kategorie ID'].unique()\n",
    "products = tickets['Produkt Label'].unique()\n",
    "\n",
    "print(categories, len(categories))\n",
    "print(products, len(products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest Messages by Group\n",
    "# tickets.groupby(['Produkt Label (Merged)'])['Timestamp'].max()\n",
    "\n",
    "# Remove Celonis & Business by Design because they haven't received messages for months\n",
    "# tickets = ticketsALL[(ticketsALL['Produkt Label (Merged)'] != 'Celonis') & (ticketsALL['Produkt Label (Merged)'] != 'Business By Design')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('All Tickets Count:', tickets.count())\n",
    "# single_correct_tickets = tickets[-tickets['New Labels'].str.contains(',')]\n",
    "# # print('All Error Tickets Count:', single_incorrect_tickets.count())\n",
    "# single_correct_tickets = single_correct_tickets[['Text', 'Beschreibung', 'Kategorie ID', 'Unterkategorie ID', 'stemmed_text', 'stemmed_beschreibung', 'Produkt Label (Merged)', 'New Labels']]\n",
    "# single_correct_tickets.head()\n",
    "# single_correct_tickets.to_excel('~/Desktop/correct_tickets.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "errors = pd.read_excel(\"~/Desktop/error_tickets.xlsx\")\n",
    "\n",
    "unclassifiables = errors[errors['RF Preds'] != errors['Produkt Label (Merged)']]\n",
    "# unclassifiables.to_excel(\"~/Desktop/unclassifiables.xlsx\")\n",
    "\n",
    "print(len(unclassifiables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_labels = len(np.unique(single_incorrect_tickets['Produkt Label (Merged)'].to_numpy()))\n",
    "\n",
    "# assert len(np.unique(tickets['Produkt Label (Merged)'].to_numpy())) == len(np.unique(single_incorrect_tickets['Produkt Label (Merged)'].to_numpy()))\n",
    "\n",
    "def get_single_label_data(sample_table, x_category_col_keys, y_col_key, test_size = 0.2):\n",
    "    x_col_keys = ['stemmed_text', 'stemmed_beschreibung'] + x_category_col_keys\n",
    "\n",
    "    if 0 < test_size:\n",
    "        x_train_raw, x_test_raw, y_train, y_test = train_test_split(\n",
    "            sample_table[x_col_keys], # x\n",
    "            sample_table[y_col_key].to_numpy(), # y\n",
    "            test_size = test_size,\n",
    "            random_state = 1)\n",
    "    else:\n",
    "        x_train_raw = sample_table[x_col_keys] # x\n",
    "        x_test_raw = x_train_raw\n",
    "        y_train = sample_table[y_col_key].to_numpy()\n",
    "        y_test = y_train\n",
    "\n",
    "    # Tfidf vectorization for the training set\n",
    "    # TEXT column\n",
    "    tfidf_vectorizer_text = TfidfVectorizer(max_features = 30)\n",
    "    tfidf_matrix_text_train = tfidf_vectorizer_text.fit_transform(x_train_raw['stemmed_text'].values.astype('U'))\n",
    "    # DESCRIPTION column\n",
    "    tfidf_vectorizer_description = TfidfVectorizer(max_features = 30)\n",
    "    tfidf_matrix_description_train = tfidf_vectorizer_description.fit_transform(x_train_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "    # Combine the Tfidf train-matrices horizontally\n",
    "    tfidf_matrix_combined_train = hstack((tfidf_matrix_text_train, tfidf_matrix_description_train))\n",
    "\n",
    "    # Tfidf vectorization for the testing set\n",
    "    # TEXT and DECRIPTION column\n",
    "    tfidf_matrix_text_test = tfidf_vectorizer_text.transform(x_test_raw['stemmed_text'].values.astype('U'))\n",
    "    tfidf_matrix_description_test = tfidf_vectorizer_description.transform(x_test_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "    # Combine the Tfidf test-matrices horizontally\n",
    "    tfidf_matrix_combined_test = hstack((tfidf_matrix_text_test, tfidf_matrix_description_test))\n",
    "\n",
    "    # 6b. Combining categorical and text data\n",
    "    # One-hot encoding for categorical data\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "    encoded_data_train = encoder.fit_transform(x_train_raw[categorical_columns]).toarray()\n",
    "    encoded_data_test = encoder.transform(x_test_raw[categorical_columns]).toarray()\n",
    "\n",
    "    # Convert the one-hot encoded arrays to sparse matrices\n",
    "    encoded_sparse_train = scipy.sparse.csr_matrix(encoded_data_train)\n",
    "    encoded_sparse_test = scipy.sparse.csr_matrix(encoded_data_test)\n",
    "\n",
    "    # Combine TF-IDF matrix and one hot encoded matrix horizontally for both training and testing sets\n",
    "    x_train = hstack((tfidf_matrix_combined_train, encoded_sparse_train))\n",
    "    x_test = hstack((tfidf_matrix_combined_test, encoded_sparse_test))\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def classify_with_metrics(classifier, x_train, y_train, x_test, y_test, description = ''):\n",
    "    clf_name = classifier.__class__.__name__\n",
    "\n",
    "    # Initializing and prediction\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "\n",
    "    # See if pnadas can handle this shit\n",
    "    # tickets[f'{clf_name} Predictions'] = classifier.predict(x_test)\n",
    "    # y_pred = tickets[f'{clf_name} Predictions']\n",
    "    # tickets[f'{clf_name} Predictions'].count()\n",
    "\n",
    "    # Performance evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average= 'weighted')\n",
    "    f1_scr = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Worst missclassified labels\n",
    "    # upper_triangle = np.triu(conf_matrix, k = 1)\n",
    "    # worst_indices = np.unravel_index(np.argmax(upper_triangle), upper_triangle.shape)\n",
    "    # worst_one = worst_indices[0]\n",
    "    # worst_two = worst_indices[1]\n",
    "\n",
    "    # Evaluation metrics output\n",
    "    print(f'Metrics for {clf_name}')\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1-Score:', f1_scr)\n",
    "    # print('Biggest error betwenen:', worst_one, 'and', worst_two)\n",
    "    \n",
    "    # Confusion Matrix Display\n",
    "    # cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels = np.unique(y_test))\n",
    "    # cm_display.plot(cmap = \"Blues\", values_format = \"d\", xticks_rotation = 'vertical')\n",
    "    # plt.title('Confusion Matrix')\n",
    "    # plt.xlabel('Predicted Label')\n",
    "    # plt.ylabel('True Label')\n",
    "    # plt.savefig(f\"single_{description}_{clf_name}_confusion_matrix.jpg\", format = 'jpg', dpi = 300, bbox_inches = 'tight')\n",
    "    # plt.show()\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Check for sparse matrices and convert to dense if necessary\n",
    "    x_train_dense = x_train.toarray() if scipy.sparse.issparse(x_train) else x_train\n",
    "    x_test_dense = x_test.toarray() if scipy.sparse.issparse(x_test) else x_test\n",
    "    x_train_dense = x_train_dense.astype('float64')\n",
    "    x_test_dense = x_test_dense.astype('float64')    \n",
    "\n",
    "     # SHAP analysis\n",
    "    try:\n",
    "        if isinstance(classifier, RandomForestClassifier):\n",
    "            explainer = shap.TreeExplainer(classifier)\n",
    "            shap_values = explainer.shap_values(x_test_dense, check_additivity=False)\n",
    "        elif isinstance(classifier, (LogisticRegression, SVC, KNeighborsClassifier, MultinomialNB)):\n",
    "            explainer = shap.KernelExplainer(lambda x: classifier.predict(x), x_train_dense)\n",
    "            shap_values = explainer.shap_values(x_test_dense)\n",
    "\n",
    "        # Plot the SHAP summary plot and save it as an image\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values, x_test_dense, plot_type=\"bar\")\n",
    "        plt.savefig(f\"shap_summary_{clf_name}_{description}.png\", format=\"png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "        # Also save the beeswarm plot (standard SHAP summary)\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values, x_test_dense)\n",
    "        plt.savefig(f\"shap_beeswarm_{clf_name}_{description}.png\", format=\"png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP not available for this classifier: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BERT Encoding\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # 1. Load a pretrained Sentence Transformer model\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# def encode_data_BERT(sample_table, x_category_col_keys, y_col_key, test_size = 0.2):\n",
    "#     x_col_keys = ['stemmed_text', 'stemmed_beschreibung'] + x_category_col_keys\n",
    "\n",
    "#     if 0 < test_size:\n",
    "#         x_train_raw, x_test_raw, y_train, y_test = train_test_split(\n",
    "#             sample_table[x_col_keys], # x\n",
    "#             sample_table[y_col_key].to_numpy(), # y\n",
    "#             test_size = test_size,\n",
    "#             random_state = 1)\n",
    "#     else:\n",
    "#         x_train_raw = sample_table[x_col_keys] # x\n",
    "#         x_test_raw = x_train_raw\n",
    "#         y_train = sample_table[y_col_key].to_numpy()\n",
    "#         y_test = y_train\n",
    "\n",
    "\n",
    "#     # 2. Calculate embeddings by calling model.encode()\n",
    "#     train_text_embedding = model.encode(x_train_raw['stemmed_text'].values.astype('U'))\n",
    "#     train_description_embedding = model.encode(x_train_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "#     combined_train = hstack((scipy.sparse.csr_matrix(train_text_embedding), train_description_embedding))\n",
    "\n",
    "#     test_text_embedding = model.encode(x_test_raw['stemmed_text'].values.astype('U'))\n",
    "#     test_description_embedding = model.encode(x_test_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "#     combined_test = hstack((scipy.sparse.csr_matrix(test_text_embedding), test_description_embedding))\n",
    "\n",
    "\n",
    "#     encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "#     encoded_data_train = encoder.fit_transform(x_train_raw[categorical_columns]).toarray()\n",
    "#     encoded_data_test = encoder.transform(x_test_raw[categorical_columns]).toarray()\n",
    "\n",
    "#     # Convert the one-hot encoded arrays to sparse matrices\n",
    "#     encoded_sparse_train = scipy.sparse.csr_matrix(encoded_data_train)\n",
    "#     encoded_sparse_test = scipy.sparse.csr_matrix(encoded_data_test)\n",
    "\n",
    "#     # Combine TF-IDF matrix and one hot encoded matrix horizontally for both training and testing sets\n",
    "#     x_train = hstack((combined_train, encoded_sparse_train))\n",
    "#     x_test = hstack((combined_test, encoded_sparse_test))\n",
    "\n",
    "#     return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BERT Implementation\n",
    "# y_col_key = 'Produkt Label (Merged)'\n",
    "\n",
    "# classification_description = 'BERT'\n",
    "\n",
    "# x_train, x_test, y_train, y_test = encode_data_BERT(tickets, categorical_columns, y_col_key, 0.2)\n",
    "\n",
    "# print('Number training samples:', len(y_train))\n",
    "# print('Number test samples:', len(y_test))\n",
    "\n",
    "# # RandomForest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 1)\n",
    "# classify_with_metrics(rf_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # SVM classifier\n",
    "# svm_classifier = SVC(kernel = 'linear', random_state = 1) # I tried all and linear is best\n",
    "# classify_with_metrics(svm_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # Naive Bayes classifier\n",
    "# # nb_classifier = MultinomialNB()\n",
    "# # classify_with_metrics(nb_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # LogReg 'max_iter' was increased from its default value because it threw a an erro in later execution \n",
    "# # for not converging when kept at 100\n",
    "# # Logistic Regression classifier\n",
    "# # logreg_classifier = LogisticRegression(random_state = 1, max_iter = 200)\n",
    "# # classify_with_metrics(logreg_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # KNN classifier\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "# classify_with_metrics(knn_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # LSW: I want to see a Perceptron Approach\n",
    "# # sgd_classifier = SGDClassifier(loss=\"perceptron\", learning_rate=\"constant\", eta0=0.02)\n",
    "# # classify_with_metrics(sgd_classifier, x_train, y_train, x_test, y_test, classification_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Default GBI/GBL unmerged\n",
    "# y_col_key = 'Produkt Label (Merged)'\n",
    "\n",
    "# classification_description = 'merged_bike'\n",
    "\n",
    "# x_train, x_test, y_train, y_test = get_single_label_data(tickets, categorical_columns, y_col_key, 0.2)\n",
    "\n",
    "# print('Number training samples:', len(y_train))\n",
    "# print('Number test samples:', len(y_test))\n",
    "\n",
    "# # RandomForest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 1)\n",
    "# classify_with_metrics(rf_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # SVM classifier\n",
    "# svm_classifier = SVC(kernel = 'linear', random_state = 1) # tried all, linear is best\n",
    "# classify_with_metrics(svm_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # Naive Bayes classifier\n",
    "# nb_classifier = MultinomialNB()\n",
    "# classify_with_metrics(nb_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # LogReg 'max_iter' was increased from its default value because it threw a an erro in later execution \n",
    "# # for not converging when kept at 100\n",
    "# # Logistic Regression classifier\n",
    "# logreg_classifier = LogisticRegression(random_state = 1, max_iter = 200)\n",
    "# classify_with_metrics(logreg_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # KNN classifier\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "# classify_with_metrics(knn_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # LSW: I want to see a Perceptron Approach\n",
    "# # sgd_classifier = SGDClassifier(loss=\"perceptron\", learning_rate=\"constant\", eta0=0.02)\n",
    "# # classify_with_metrics(sgd_classifier, x_train, y_train, x_test, y_test, classification_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bike Internal Classification\n",
    "# y_col_key = 'Produkt Label'\n",
    "\n",
    "# bike_tickets = tickets[tickets['Produkt Label (Merged)'] == 'global bike']\n",
    "\n",
    "# classification_description = 'bike_internal_accurate'\n",
    "\n",
    "# # print('Number training samples:', len(y_train))\n",
    "# # print('Number test samples:', len(y_test))\n",
    "\n",
    "# # RandomForest classifier\n",
    "# x_train, x_test, y_train, y_test = get_single_label_data(bike_tickets[bike_tickets['RandomForestClassifier Predictions'] == 'global bike'], categorical_columns, y_col_key, 0.2)\n",
    "# rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 1)\n",
    "# classify_with_metrics(rf_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # SVM classifier\n",
    "# x_train, x_test, y_train, y_test = get_single_label_data(bike_tickets[bike_tickets['SVC Predictions'] == 'global bike'], categorical_columns, y_col_key, 0.2)\n",
    "# svm_classifier = SVC(kernel = 'linear', random_state = 1)\n",
    "# classify_with_metrics(svm_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # Naive Bayes classifier\n",
    "# x_train, x_test, y_train, y_test = get_single_label_data(bike_tickets[bike_tickets['MultinomialNB Predictions'] == 'global bike'], categorical_columns, y_col_key, 0.2)\n",
    "# nb_classifier = MultinomialNB()\n",
    "# classify_with_metrics(nb_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # LogReg 'max_iter' was increased from its default value because it threw a an erro in later execution \n",
    "# # for not converging when kept at 100\n",
    "# # Logistic Regression classifier\n",
    "# x_train, x_test, y_train, y_test = get_single_label_data(bike_tickets[bike_tickets['LogisticRegression Predictions'] == 'global bike'], categorical_columns, y_col_key, 0.2)\n",
    "# logreg_classifier = LogisticRegression(random_state = 1, max_iter = 200)\n",
    "# classify_with_metrics(logreg_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # KNN classifier\n",
    "# x_train, x_test, y_train, y_test = get_single_label_data(bike_tickets[bike_tickets['KNeighborsClassifier Predictions'] == 'global bike'], categorical_columns, y_col_key, 0.2)\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "# classify_with_metrics(knn_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # # LSW: I want to see a Perceptron Approach\n",
    "# # sgd_classifier = SGDClassifier(loss=\"perceptron\", learning_rate=\"constant\", eta0=0.02)\n",
    "# # classify_with_metrics(sgd_classifier, x_train, y_train, x_test, y_test, classification_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "# single_incorrect_tickets = tickets[tickets['error_count'] > 0]\n",
    "\n",
    "# pred_columns = ['RandomForestClassifier Predictions', 'SVC Predictions', 'MultinomialNB Predictions',\n",
    "#                 'LogisticRegression Predictions', 'KNeighborsClassifier Predictions']\n",
    "\n",
    "# # Extract the relevant prediction columns\n",
    "# predictions_df = single_incorrect_tickets[pred_columns].copy()\n",
    "\n",
    "# # Initialize label encoders for each column and encode the predictions into numerical form\n",
    "# label_encoders = {}\n",
    "# for col in pred_columns:\n",
    "#     le = LabelEncoder()\n",
    "#     predictions_df[col] = le.fit_transform(predictions_df[col])\n",
    "#     label_encoders[col] = le  # Store label encoders if needed later for decoding\n",
    "\n",
    "# # Get the number of unique categories (classes) in the predictions\n",
    "# categories = len(np.unique(predictions_df.values))\n",
    "\n",
    "# # Build a matrix where each row contains the vote counts for each category\n",
    "# # This is required for Fleiss' Kappa calculation\n",
    "# kappa_matrix = []\n",
    "# for row in predictions_df.values:\n",
    "#     vote_counts = [list(row).count(c) for c in range(categories)]\n",
    "#     kappa_matrix.append(vote_counts)\n",
    "\n",
    "# # Convert the matrix into a DataFrame\n",
    "# kappa_matrix_df = pd.DataFrame(kappa_matrix)\n",
    "\n",
    "# # Compute Fleiss' Kappa using the transformed data\n",
    "# kappa_value = fleiss_kappa(kappa_matrix_df)\n",
    "\n",
    "# # Output the result\n",
    "# print(f\"Fleiss' Kappa: {kappa_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Incorrectly Labelled Data only with GBI/GBL merged\n",
    "# single_incorrect_tickets = tickets[tickets['error_count'] > 0]\n",
    "# # single_incorrect_tickets = single_incorrect_tickets[['Text', 'Beschreibung', 'Kategorie ID', 'Unterkategorie ID', 'stemmed_text', 'stemmed_beschreibung', 'Produkt Label (Merged)', 'New Labels']]\n",
    "# # single_incorrect_tickets.head()\n",
    "# # single_incorrect_tickets.to_excel('~/Desktop/error_tickets.xlsx')\n",
    "\n",
    "# y_col_key = 'Produkt Label (Merged)'\n",
    "\n",
    "# x_train, x_test, y_train, y_test = get_single_label_data(single_incorrect_tickets, categorical_columns, y_col_key, 0.2)\n",
    "\n",
    "# classification_description = 'merged_bike_incorrect_labels_only'\n",
    "\n",
    "# print('Number training samples:', len(y_train))\n",
    "# print('Number test samples:', len(y_test))\n",
    "\n",
    "# # RandomForest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 1)\n",
    "# classify_with_metrics(rf_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # SVM classifier\n",
    "# svm_classifier = SVC(kernel = 'linear', random_state = 1)\n",
    "# classify_with_metrics(svm_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # Naive Bayes classifier\n",
    "# nb_classifier = MultinomialNB()\n",
    "# classify_with_metrics(nb_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # LogReg 'max_iter' was increased from its default value because it threw a an erro in later execution \n",
    "# # for not converging when kept at 100\n",
    "# # Logistic Regression classifier\n",
    "# logreg_classifier = LogisticRegression(random_state = 1, max_iter = 200)\n",
    "# classify_with_metrics(logreg_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # KNN classifier\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "# classify_with_metrics(knn_classifier, x_train, y_train, x_test, y_test, classification_description)\n",
    "\n",
    "# # LSW: I want to see a Perceptron Approach\n",
    "# sgd_classifier = SGDClassifier(loss=\"perceptron\", learning_rate=\"constant\", eta0=0.02)\n",
    "# classify_with_metrics(sgd_classifier, x_train, y_train, x_test, y_test, classification_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = tickets['New Labels'].map(lambda labels_str: labels_str.split(','))\n",
    "\n",
    "# # classes = list(set(tickets['Produkt Label (Merged)']))\n",
    "# multi_binarizer = MultiLabelBinarizer()\n",
    "# multi_binarizer.fit(labels)\n",
    "\n",
    "# def get_multi_label_data(test_size = 0.2):\n",
    "#     x_train_raw, x_test_raw, y_train, y_test = train_test_split(\n",
    "#         tickets[['stemmed_text', 'stemmed_beschreibung'] + categorical_columns], # x\n",
    "#         labels, # y\n",
    "#         test_size = test_size,\n",
    "#         random_state = 1)\n",
    "\n",
    "#     y_train = multi_binarizer.transform(y_train)\n",
    "#     y_test = multi_binarizer.transform(y_test)\n",
    "\n",
    "#     # Tfidf vectorization for the training set\n",
    "#     # TEXT column\n",
    "#     tfidf_vectorizer_text = TfidfVectorizer(max_features = 30)\n",
    "#     tfidf_matrix_text_train = tfidf_vectorizer_text.fit_transform(x_train_raw['stemmed_text'].values.astype('U'))\n",
    "#     # DESCRIPTION column\n",
    "#     tfidf_vectorizer_description = TfidfVectorizer(max_features = 30)\n",
    "#     tfidf_matrix_description_train = tfidf_vectorizer_description.fit_transform(x_train_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "#     # Combine the Tfidf train-matrices horizontally\n",
    "#     tfidf_matrix_combined_train = hstack((tfidf_matrix_text_train, tfidf_matrix_description_train))\n",
    "\n",
    "#     # Tfidf vectorization for the testing set\n",
    "#     # TEXT and DECRIPTION column\n",
    "#     tfidf_matrix_text_test = tfidf_vectorizer_text.transform(x_test_raw['stemmed_text'].values.astype('U'))\n",
    "#     tfidf_matrix_description_test = tfidf_vectorizer_description.transform(x_test_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "#     # Combine the Tfidf test-matrices horizontally\n",
    "#     tfidf_matrix_combined_test = hstack((tfidf_matrix_text_test, tfidf_matrix_description_test))\n",
    "\n",
    "#     # 6b. Combining categorical and text data\n",
    "#     # One-hot encoding for categorical data\n",
    "#     encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "#     encoded_data_train = encoder.fit_transform(x_train_raw[categorical_columns]).toarray()\n",
    "#     encoded_data_test = encoder.transform(x_test_raw[categorical_columns]).toarray()\n",
    "\n",
    "#     # Convert the one-hot encoded arrays to sparse matrices\n",
    "#     encoded_sparse_train = scipy.sparse.csr_matrix(encoded_data_train)\n",
    "#     encoded_sparse_test = scipy.sparse.csr_matrix(encoded_data_test)\n",
    "\n",
    "#     # Combine TF-IDF matrix and one hot encoded matrix horizontally for both training and testing sets\n",
    "#     x_train = hstack((tfidf_matrix_combined_train, encoded_sparse_train))\n",
    "#     x_test = hstack((tfidf_matrix_combined_test, encoded_sparse_test))\n",
    "\n",
    "#     return x_train, x_test, y_train, y_test\n",
    "\n",
    "# #print(final_matrix_train)\n",
    "\n",
    "# # Classification and evaluation in one method with different classifiers as parameter\n",
    "# def multiclassify_with_metrics(classifier, x_train, y_train, x_test, y_test):\n",
    "#     clf_name = 'Multi Label ' + classifier.__class__.__name__\n",
    "\n",
    "#     # Initializing and prediction\n",
    "#     multi_clf = MultiOutputClassifier(classifier).fit(x_train, y_train)\n",
    "#     y_pred = multi_clf.predict(x_test)\n",
    "    \n",
    "#     # Performance evaluation\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred, average = 'weighted', zero_division=1)\n",
    "#     recall = recall_score(y_test, y_pred, average= 'weighted')\n",
    "#     f1_scr = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "#     # str_pred = multi_binarizer.inverse_transform(y_pred)\n",
    "#     # str_test = multi_binarizer.inverse_transform(y_test)\n",
    "#     # print(str_pred)\n",
    "#     # print(str_test)\n",
    "\n",
    "#     conf_matrix = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#     # Worst missclassified labels\n",
    "#     # upper_triangle = np.triu(conf_matrix, k = 1)\n",
    "#     # worst_indices = np.unravel_index(np.argmax(upper_triangle), upper_triangle.shape)\n",
    "#     # worst_one = worst_indices[0]\n",
    "#     # worst_two = worst_indices[1]\n",
    "\n",
    "#     # Evaluation metrics output\n",
    "#     print(f'Metrics for {clf_name}')\n",
    "#     print('ALL COMPARISONS FOR THE METRICS WERE BETWEEN SETS WHICH MUST CONTAIN IDENTICAL ELEMENTS')\n",
    "#     print('Accuracy:', accuracy)\n",
    "#     print('Precision:', precision)\n",
    "#     print('Recall:', recall)\n",
    "#     print('F1-Score:', f1_scr)\n",
    "#     # print('Biggest error betwenen:', worst_one, 'and', worst_two)\n",
    "    \n",
    "#     # Confusion Matrix Display\n",
    "#     fig, axes = plt.subplots(3, 5, figsize=(25, 15))\n",
    "#     axes = axes.ravel()\n",
    "\n",
    "#     for class_index in range(0, conf_matrix.shape[0]):\n",
    "#         class_name = multi_binarizer.classes_[class_index]\n",
    "#         class_conf_mat = conf_matrix[class_index]\n",
    "\n",
    "#         cm_display = ConfusionMatrixDisplay(class_conf_mat, display_labels=['True', 'False'])\n",
    "#         cm_display.plot(ax=axes[class_index], cmap = \"Blues\", values_format = \"d\", xticks_rotation = 'vertical')\n",
    "#         cm_display.ax_.set_title(class_name)\n",
    "#         plt.xlabel('Predicted Label')\n",
    "#         plt.ylabel('True Label')\n",
    "#         cm_display.im_.colorbar.remove()\n",
    "\n",
    "#     plt.subplots_adjust(wspace=0.25, hspace=0.35)\n",
    "#     # f.colorbar(disp.im_, ax=axes)\n",
    "#     fig.delaxes(axes[14])\n",
    "#     fig.suptitle(f'{clf_name} Confusion Matrices', fontsize=16, y=0.03)\n",
    "#     plt.show()\n",
    "\n",
    "#     fig.savefig(f\"{clf_name}_confusion_matrix.jpg\", format = 'jpg', dpi = 300, bbox_inches = 'tight')\n",
    "\n",
    "#     print('/n')\n",
    "    \n",
    "# x_train, x_test, y_train, y_test = get_multi_label_data()\n",
    "\n",
    "# # RandomForest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 1)\n",
    "# multiclassify_with_metrics(rf_classifier, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# # SVM classifier\n",
    "# svm_classifier = SVC(kernel = 'linear', random_state = 1)\n",
    "# multiclassify_with_metrics(svm_classifier, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# # Naive Bayes classifier\n",
    "# nb_classifier = MultinomialNB()\n",
    "# multiclassify_with_metrics(nb_classifier, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# # LogReg 'max_iter' was increased from its default value because it threw a an erro in later execution \n",
    "# # for not converging when kept at 100\n",
    "# # Logistic Regression classifier\n",
    "# logreg_classifier = LogisticRegression(random_state = 1, max_iter = 200)\n",
    "# multiclassify_with_metrics(logreg_classifier, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# # KNN classifier\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "# multiclassify_with_metrics(knn_classifier, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# # LSW: I want to see a Perceptron Approach\n",
    "# sgd_classifier = SGDClassifier(loss=\"perceptron\", learning_rate=\"constant\", eta0=0.02)\n",
    "# multiclassify_with_metrics(sgd_classifier, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Example 2D array\n",
    "# inputs = np.random.rand(2166, 177)\n",
    "\n",
    "# # Print the shape to confirm\n",
    "# print(f\"Shape of inputs: {inputs.__class__}\")\n",
    "\n",
    "# # Calculate standard deviation\n",
    "# std_deviation = np.std(inputs, axis=0)\n",
    "# print(\"Standard deviation for each column:\", std_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data's General Discrimination Value: -0.008704462732936286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_gdv(inputs, labels):\n",
    "    # Step 1: Data Normalization\n",
    "    N, D = inputs.shape\n",
    "    normalized_data = np.zeros_like(inputs)\n",
    "\n",
    "    for d in range(D):\n",
    "        mu_d = np.mean(inputs[:, d])\n",
    "        sigma_d = np.std(inputs[:, d])\n",
    "        normalized_data[:, d] = 0.5 * (inputs[:, d] - mu_d) / sigma_d\n",
    "\n",
    "    # Step 2: Intra-Class Distance\n",
    "    unique_labels = np.unique(labels)\n",
    "    L = len(unique_labels)\n",
    "    intra_class_distances = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        class_points = normalized_data[labels == label]\n",
    "        N_l = class_points.shape[0]\n",
    "        if N_l < 2:\n",
    "            continue  # Skip classes with less than 2 points\n",
    "\n",
    "        # Compute mean intra-class distance\n",
    "        intra_distance = 0\n",
    "        for i in range(N_l - 1):\n",
    "            for j in range(i + 1, N_l):\n",
    "                intra_distance += np.linalg.norm(class_points[i] - class_points[j])\n",
    "\n",
    "        mean_intra_distance = (2 * intra_distance) / (N_l * (N_l - 1))\n",
    "        intra_class_distances.append(mean_intra_distance)\n",
    "\n",
    "    # Step 3: Inter-Class Distance\n",
    "    inter_class_distances = []\n",
    "    \n",
    "    for i in range(L):\n",
    "        for j in range(i + 1, L):\n",
    "            class_points_l = normalized_data[labels == unique_labels[i]]\n",
    "            class_points_m = normalized_data[labels == unique_labels[j]]\n",
    "            N_l = class_points_l.shape[0]\n",
    "            N_m = class_points_m.shape[0]\n",
    "\n",
    "            inter_distance = 0\n",
    "            for point_l in class_points_l:\n",
    "                for point_m in class_points_m:\n",
    "                    inter_distance += np.linalg.norm(point_l - point_m)\n",
    "\n",
    "            mean_inter_distance = inter_distance / (N_l * N_m)\n",
    "            inter_class_distances.append(mean_inter_distance)\n",
    "\n",
    "    # Step 4: GDV Calculation\n",
    "    mean_intra = np.mean(intra_class_distances) if intra_class_distances else 0\n",
    "    mean_inter = np.mean(inter_class_distances) if inter_class_distances else 0\n",
    "\n",
    "    gdv = (1 / np.sqrt(D)) * (mean_intra - (2 / (L * (L - 1))) * np.sum(inter_class_distances))\n",
    "\n",
    "    # Step 5: Final GDV\n",
    "    gdv_final = (1 / np.sqrt(D)) * gdv\n",
    "\n",
    "    return gdv_final\n",
    "\n",
    "\n",
    "# Sample function call\n",
    "y_col_key = 'Produkt Label'\n",
    "inputs, _, labels, _ = get_single_label_data(tickets, categorical_columns, y_col_key, 1)\n",
    "inputs = inputs.toarray()\n",
    "\n",
    "print(\"Our data's General Discrimination Value:\", compute_gdv(inputs, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
