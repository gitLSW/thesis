{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSW Mu;i Labelled Classification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy.sparse\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from collections.abc import Sequence, Set\n",
    "\n",
    "dataset_dir_path = \"~/Desktop/Tickets\"\n",
    "categorical_columns = ['Kategorie ID', 'Unterkategorie ID']\n",
    "\n",
    "tickets = pd.read_csv(f\"{dataset_dir_path}/tickets.csv\")\n",
    "\n",
    "tickets.head()\n",
    "# tickets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def encode_data_BERT(sample_table, x_category_col_keys, y_col_key, test_size = 0.2):\n",
    "    x_col_keys = ['stemmed_text', 'stemmed_beschreibung'] + x_category_col_keys\n",
    "\n",
    "    if 0 < test_size:\n",
    "        x_train_raw, x_test_raw, y_train, y_test = train_test_split(\n",
    "            sample_table[x_col_keys], # x\n",
    "            sample_table[y_col_key].to_numpy(), # y\n",
    "            test_size = test_size,\n",
    "            random_state = 1)\n",
    "    else:\n",
    "        x_train_raw = sample_table[x_col_keys] # x\n",
    "        x_test_raw = x_train_raw\n",
    "        y_train = sample_table[y_col_key].to_numpy()\n",
    "        y_test = y_train\n",
    "\n",
    "\n",
    "    # 2. Calculate embeddings by calling model.encode()\n",
    "    train_text_embeddings = model.encode(x_train_raw['stemmed_text'].values.astype('U'))\n",
    "    train_description_embedding = model.encode(x_train_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "    combined_train = hstack((train_text_embeddings, train_description_embedding))\n",
    "\n",
    "    test_text_embeddings = model.encode(x_test_raw['stemmed_text'].values.astype('U'))\n",
    "    test_description_embedding = model.encode(x_test_raw['stemmed_beschreibung'].values.astype('U'))\n",
    "    combined_test = hstack((test_text_embeddings, test_description_embedding))\n",
    "\n",
    "\n",
    "    encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "    encoded_data_train = encoder.fit_transform(x_train_raw[categorical_columns]).toarray()\n",
    "    encoded_data_test = encoder.transform(x_test_raw[categorical_columns]).toarray()\n",
    "\n",
    "    # Convert the one-hot encoded arrays to sparse matrices\n",
    "    encoded_sparse_train = scipy.sparse.csr_matrix(encoded_data_train)\n",
    "    encoded_sparse_test = scipy.sparse.csr_matrix(encoded_data_test)\n",
    "\n",
    "    # Combine TF-IDF matrix and one hot encoded matrix horizontally for both training and testing sets\n",
    "    x_train = hstack((combined_train, encoded_sparse_train))\n",
    "    x_test = hstack((combined_test, encoded_sparse_test))\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
